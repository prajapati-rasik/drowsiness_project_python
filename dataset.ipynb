{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "# opencv-python is a open source library that allow us to access APIs used for the computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv2.CascadeClassifier('./haar cascade files/haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('./haar cascade files/haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('./haar cascade files/haarcascade_righteye_2splits.xml')\n",
    "# these are xml files downloaded from google for detecting face ,left_eye and right_eye\n",
    "# Haar Cascades use machine learning techniques in which a function is trained from a lot of positive and negative images. \n",
    "# This process in the algorithm is called feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder hierarchy\n",
    "<pre>images -> training images -> open<br>\n",
    "                          -> closed<br>\n",
    "       -> validation images -> open<br>\n",
    "                            -> closed<br>\n",
    "       -> test images -> open<br>\n",
    "                      -> closed<br></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for capturing images for validation set , just change training_images folder to validation_images \n",
    "### and for testing set , just change training_images folder to test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing pictures of open eyes for training\n",
    "# keep your eyes open while capturing video\n",
    "\n",
    "cap = cv2.VideoCapture(0) # intializing video capture object\n",
    "count=0 # count variable for giving index to image\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    # detecting face,left eye and right eye   \n",
    "    faces = face.detectMultiScale(frame,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    # it will ignore the images which are smaller than (25,25)\n",
    "    # minNeigh specifying how many neighbors each candidate rectangle should have to retain it.This is a detection \n",
    "    # algorithm that uses a moving window to detect objects, it does so by defining how many objects are found near the current one before it can declare the face found.\n",
    "    left_eye = leye.detectMultiScale(frame)\n",
    "    right_eye =  reye.detectMultiScale(frame)\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    # give path for saving images of right eye and left eye in open folder  \n",
    "    output1 = \"Drowsiness detection/images/training_images/open/image\"+str(count)+\".jpg\"\n",
    "    output2 = \"Drowsiness detection/images/training_images/open/image\"+str(count+1)+\".jpg\"\n",
    "    \n",
    "    for (x,y,w,h) in right_eye:  # right_eye object has coordinates of upper left corner , width and height\n",
    "        r_eye=frame[y:y+h,x:x+w]  # extracting right eye\n",
    "        cv2.imwrite(output1,r_eye)  # saving image to the output path\n",
    "        \n",
    "    for (x,y,w,h) in left_eye:  \n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        cv2.imwrite(output2,l_eye)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    count+=2\n",
    "    if cv2.waitKey(1) == ord('q'): # if q is pressed loop will break\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing pictures of closed eyes\n",
    "# keep your eyes close while capturing video\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count=0\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    faces = face.detectMultiScale(frame,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    left_eye = leye.detectMultiScale(frame)\n",
    "    right_eye =  reye.detectMultiScale(frame)\n",
    "    \n",
    "    # path for the images , insert into closed folder\n",
    "    output1 = \"Drowsiness detection/images/training_images/closed/img\"+str(count)+\".jpg\"\n",
    "    output2 = \"Drowsiness detection/images/training_images/closed/img\"+str(count+1)+\".jpg\"\n",
    "    \n",
    "    for (x,y,w,h) in right_eye:\n",
    "        r_eye=frame[y:y+h,x:x+w]\n",
    "        cv2.imwrite(output1,r_eye)\n",
    "        \n",
    "    for (x,y,w,h) in left_eye:\n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        cv2.imwrite(output2,l_eye)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    count+=2\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
